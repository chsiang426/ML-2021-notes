<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>14-Nerwork Compression</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 10px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.callout img.notion-static-icon {
	width: 1em;
	height: 1em;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

blockquote.quote-large {
	font-size: 1.25em;
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray {
	color: rgba(128, 125, 120, 1);
	fill: rgba(128, 125, 120, 1);
}
.highlight-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.highlight-orange {
	color: rgba(204, 121, 47, 1);
	fill: rgba(204, 121, 47, 1);
}
.highlight-yellow {
	color: rgba(195, 148, 67, 1);
	fill: rgba(195, 148, 67, 1);
}
.highlight-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.highlight-blue {
	color: rgba(63, 126, 190, 1);
	fill: rgba(63, 126, 190, 1);
}
.highlight-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.highlight-pink {
	color: rgba(179, 84, 136, 1);
	fill: rgba(179, 84, 136, 1);
}
.highlight-red {
	color: rgba(201, 85, 73, 1);
	fill: rgba(201, 85, 73, 1);
}
.highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray_background {
	background: rgba(42, 28, 0, 0.07);
}
.highlight-brown_background {
	background: rgba(139, 46, 0, 0.086);
}
.highlight-orange_background {
	background: rgba(224, 101, 1, 0.129);
}
.highlight-yellow_background {
	background: rgba(211, 168, 0, 0.137);
}
.highlight-teal_background {
	background: rgba(0, 100, 45, 0.09);
}
.highlight-blue_background {
	background: rgba(0, 111, 200, 0.09);
}
.highlight-purple_background {
	background: rgba(102, 0, 178, 0.078);
}
.highlight-pink_background {
	background: rgba(197, 0, 93, 0.086);
}
.highlight-red_background {
	background: rgba(223, 22, 0, 0.094);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(128, 125, 120, 1);
	fill: rgba(128, 125, 120, 1);
}
.block-color-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.block-color-orange {
	color: rgba(204, 121, 47, 1);
	fill: rgba(204, 121, 47, 1);
}
.block-color-yellow {
	color: rgba(195, 148, 67, 1);
	fill: rgba(195, 148, 67, 1);
}
.block-color-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.block-color-blue {
	color: rgba(63, 126, 190, 1);
	fill: rgba(63, 126, 190, 1);
}
.block-color-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.block-color-pink {
	color: rgba(179, 84, 136, 1);
	fill: rgba(179, 84, 136, 1);
}
.block-color-red {
	color: rgba(201, 85, 73, 1);
	fill: rgba(201, 85, 73, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.block-color-blue_background {
	background: rgba(232, 242, 250, 1);
}
.block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.select-value-color-blue { background-color: rgba(0, 99, 174, 0.172); }
.select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	


/* Back-to-index button */
.floating-button {
	display: inline-flex;
	align-items: center;
	gap: 0.4em;
	padding: 0.55em 1.15em;
	border-radius: 999px;
	background: rgba(255, 255, 255, 0.92);
	color: #1f2933;
	font-size: 0.9rem;
	font-weight: 500;
	text-decoration: none;
	border: 1px solid rgba(15, 23, 42, 0.12);
	box-shadow: 0 8px 24px rgba(15, 23, 42, 0.12);
	backdrop-filter: blur(12px);
	transition: background-color 0.2s ease, color 0.2s ease, box-shadow 0.2s ease, transform 0.2s ease;
}
.floating-button:hover {
	background: #1f2933;
	color: #ffffff;
	box-shadow: 0 12px 32px rgba(15, 23, 42, 0.18);
	transform: translateY(-1px);
}
.floating-button:active {
	transform: translateY(0);
	box-shadow: 0 6px 18px rgba(15, 23, 42, 0.14);
}
.back-to-index {
	position: fixed;
	top: 20px;
	left: 20px;
	z-index: 1000;
}
.nav-controls {
	position: fixed;
	top: 20px;
	right: 20px;
	z-index: 1000;
	display: inline-flex;
	gap: 0.6em;
	flex-wrap: wrap;
	justify-content: flex-end;
}
@media (max-width: 600px) {
	.back-to-index {
		top: 16px;
		left: 16px;
	}
	.nav-controls {
		top: 16px;
		right: 16px;
		gap: 0.5em;
	}
	.floating-button {
		padding: 0.45em 1em;
		font-size: 0.85rem;
	}
}
@media print {
	.back-to-index,
	.nav-controls {
		display: none;
	}
}

</style></head><body>
<a class="floating-button back-to-index" href="../index.html">回到目錄</a>
<div class="nav-controls">
	<a class="floating-button nav-button" href="../13-Life Long Learning（終身學習）/13-Life Long Learning（終身學習）.html" title="上一節：13-Life Long Learning（終身學習）">上一節</a>
	<a class="floating-button nav-button" href="../15-Meta Learning（元學習）/15-Meta Learning（元學習）.html" title="下一節：15-Meta Learning（元學習）">下一節</a>
</div>
<article id="4bae9dc8-2e1c-4e06-938d-3637e6e966f9" class="page sans"><header><div class="page-header-icon undefined"><img class="icon notion-static-icon" src="https://www.notion.so/icons/document_blue.svg"/></div><h1 class="page-title">14-Nerwork Compression</h1><p class="page-description"></p><table class="properties"><tbody></tbody></table></header><div class="page-body"><nav id="c39c3e20-22ac-4ab3-9a35-5d3e2c583602" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#7d3822d6-e110-462f-bfeb-20a423e58eed">1. Introduction</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#c3fe7ce6-a106-462a-bd91-eafb658ea6c3">2. Network Pruning</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ded880d6-ed7b-45c0-a1fb-24f3c43bd155">2.1 Weight pruning</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#65133de6-7a11-4519-b44d-e8550902a3e1">2.2 Neuron pruning</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#19dbc0d9-8567-49f2-91fe-db1dd82d38ad">2.3 Why Pruning？</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#1189fe2a-25e5-4934-a91e-f9704f15cb1e">2.3.1 Lottery Ticket Hypothesis</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#53365cab-726d-4f35-a2a6-3473fb23f787">2.3.2 反對大樂透假說：Rethinking the Value of Network Pruning</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#b685e458-7736-40f8-a29b-dc180426edbd">3. Knowledge Distillation</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#d08ae3ec-867d-4b8d-b761-607b104a2f04">3.1 Temperature for softmax</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#68a6c9e7-5dea-4647-ac9e-0f8f8a9359dd">4. Parameter Quantization</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ec0e6dbe-a34f-4212-93c0-375abea0d386">4.1 減少 bits 數</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#62e4fb84-e9b1-491a-baa0-2f14b4d3e8eb">4.2 Weight clustering</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#9c6e28b0-876a-40f8-8681-c30d54e2e667">4.3 Huffman encoding</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#c001ae27-55e3-49d9-8bf5-1c2b0c97412b">4.4 Binary weight</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#33971596-fb75-472f-803b-78b29a97cd0b">5. Architecture Design</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#687ddfef-106d-46d2-8889-00b9c7d35fe8">5.1 Low rank approximation</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0784a5da-6b6e-4332-ad3a-3bf169deee57">5.2 Depthwise Separable Convolution</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#b8bf8641-6cbd-456e-9fac-db6ebc23c12f">5.2.1 Depthwise Convolution</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#b43b38d5-b0fc-486e-9f1c-bb13596431f4">5.2.2 Pointwise Convolution</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0a03eb59-6081-4295-9fa5-9a938289ed63">5.3 To learn More</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#ae0a6459-3ebf-48a5-9daa-0d060ff81133">6. Dynamic Computation</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#5c1522a3-f26f-4267-84b9-03fcc9a1b6a5">6.1 Dynamic Depth</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#2d486f9a-a5e6-47ef-9594-806f94a68e52">6.2 Dynamic Width</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#84ccf902-76fe-48cd-903c-4e05c25e251f">6.3 network 自行決定深度和寬度</a></div></nav><h1 id="7d3822d6-e110-462f-bfeb-20a423e58eed" class="">1. Introduction</h1><p id="2ae3039e-5089-4e93-99f2-5c7d1f194809" class="">把模型用在資源有限的環境下，擁有比較少量的參數，但是與原模型有差不多的效能</p><figure id="ce683ac6-116d-4f53-8c9b-90eae51795e9" class="image"><a href="14-Nerwork%20Compression/0.png"><img style="width:384px" src="14-Nerwork%20Compression/0.png"/></a></figure><p id="66909f5f-f00f-4b18-92d7-8316af916fbd" class="">五個 network compression 技術（軟體導向）：</p><ol type="1" id="8d5bd779-a609-46b4-a984-5857ee1c25dc" class="numbered-list" start="1"><li><a href="https://www.notion.so/14-Nerwork-Compression-4bae9dc82e1c4e06938d3637e6e966f9?pvs=21">Network Pruning</a></li></ol><ol type="1" id="1a4d860c-3459-4c51-b6e8-4abea31d1b99" class="numbered-list" start="2"><li><a href="https://www.notion.so/14-Nerwork-Compression-4bae9dc82e1c4e06938d3637e6e966f9?pvs=21">Knowledge Distillation</a></li></ol><ol type="1" id="70ad3d7e-a174-45cd-b68c-dd419bf67d0d" class="numbered-list" start="3"><li><a href="https://www.notion.so/14-Nerwork-Compression-4bae9dc82e1c4e06938d3637e6e966f9?pvs=21">Parameter Quantization</a></li></ol><ol type="1" id="583c90ac-7972-4ee1-a714-abea12e900b3" class="numbered-list" start="4"><li><a href="https://www.notion.so/14-Nerwork-Compression-4bae9dc82e1c4e06938d3637e6e966f9?pvs=21">Architecture Design</a></li></ol><ol type="1" id="b12856f6-60c8-4127-9a4d-40505a408a01" class="numbered-list" start="5"><li><a href="https://www.notion.so/14-Nerwork-Compression-4bae9dc82e1c4e06938d3637e6e966f9?pvs=21">Dynamic Computation</a></li></ol><p id="2bbc59f3-486a-43f3-abc0-62819daeab17" class=""><strong>五種技術的前四種不互斥，可以同時使用</strong></p><p id="124ad315-f561-4a79-a9da-8588ca585c35" class="">
</p><h1 id="c3fe7ce6-a106-462a-bd91-eafb658ea6c3" class="">2. Network Pruning</h1><p id="f088ea5a-d463-40ba-8afb-abb435573cb0" class="">network 中有許多參數，有可能有些參數沒有用處，只是佔空間、浪費運算資源而已，而 <strong>network pruning 就是把 network 中沒有用的參數找出來刪除掉</strong></p><figure id="d9908925-da6d-444b-953b-0f7770f08981" class="image"><a href="14-Nerwork%20Compression/1.png"><img style="width:384px" src="14-Nerwork%20Compression/1.png"/></a></figure><ol type="1" id="006cfd6e-1f5e-4826-ad7c-bf8bc6612b36" class="numbered-list" start="1"><li>訓練一個大的模型</li></ol><ol type="1" id="b0f05490-1715-4ca8-9bfd-3d7403ad0fba" class="numbered-list" start="2"><li><strong>評估 weight 或 neuron 的重要性</strong><ul id="b747b780-bbc3-4aea-90d7-a38aef143f10" class="bulleted-list"><li style="list-style-type:disc"><strong>weight </strong>的重要性<ul id="63d2fade-ddde-49af-aded-08c69998e94a" class="bulleted-list"><li style="list-style-type:circle">參數加上絕對值得大小</li></ul><ul id="bac33b15-b88d-48a5-81fc-f547b72cd9bc" class="bulleted-list"><li style="list-style-type:circle">套用 LLL 的思想，計算 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></li></ul></li></ul><ul id="e3489709-be79-4b11-b1cf-5dc0d55c5dc3" class="bulleted-list"><li style="list-style-type:disc"><strong>neuron </strong>的重要性<ul id="c5bf6389-34ff-4481-a020-a72bb22aa636" class="bulleted-list"><li style="list-style-type:circle">計算神經元輸出不為 0 的次數</li></ul></li></ul></li></ol><ol type="1" id="e0e22179-0d2c-4465-b38c-5d7ccde70b86" class="numbered-list" start="3"><li>移除不重要的 <strong>weight </strong>或 <strong>neuron</strong>（此時模型性能可能下降）</li></ol><ol type="1" id="1d56b2ba-e5aa-483a-abb5-0b6adc523473" class="numbered-list" start="4"><li>微調模型</li></ol><ol type="1" id="e7fb398e-5769-4359-8d8a-91f6ef77f4c6" class="numbered-list" start="5"><li>重複步驟 2. 至 4.</li></ol><h3 id="ded880d6-ed7b-45c0-a1fb-24f3c43bd155" class="">2.1 Weight pruning</h3><figure id="650be930-978f-4330-8484-a1996d328cea" class="image"><a href="14-Nerwork%20Compression/2.png"><img style="width:384px" src="14-Nerwork%20Compression/2.png"/></a></figure><p id="6545d86a-2b26-491e-a9c4-378c188b1036" class=""><strong>問題：</strong></p><p id="8f9a46ee-7f9d-4353-bef6-4ab6e911ff38" class="">刪除 weight 後，神經網路形狀不規則，實作上難以實現，也難以使用 GPU 加速矩陣乘法</p><figure id="22b50c97-6e0b-4300-81be-7df3613464d8" class="image"><a href="14-Nerwork%20Compression/3.png"><img style="width:432px" src="14-Nerwork%20Compression/3.png"/></a></figure><p id="25f1186f-9d53-4c49-9566-793f6c78b4f9" class="">以上實驗結果顯示，即使剪掉 95% 的 weight，但是運算時大多時候並沒有變得更快</p><h3 id="65133de6-7a11-4519-b44d-e8550902a3e1" class="">2.2 Neuron pruning</h3><figure id="97e7a71b-339c-4cda-bf6d-11c79470dbf2" class="image"><a href="14-Nerwork%20Compression/4.png"><img style="width:384px" src="14-Nerwork%20Compression/4.png"/></a></figure><p id="dae54006-21b7-4b2f-9d64-d052c9c3fa8b" class="">容易實現，且容易加速運算</p><h2 id="19dbc0d9-8567-49f2-91fe-db1dd82d38ad" class="">2.3 Why Pruning？</h2><p id="64fe66e9-8a14-4440-a0c4-8506fdc7c456" class=""><strong>問題：</strong></p><p id="a7266bea-24af-4074-9605-5ef58e5c3d55" class="">先訓練大的 network 再把它變小，且希望小的 network 跟大的 network 正確率沒有差太多，那麽為什麽不直接訓練小的 network</p><p id="a4fd3390-e28b-43a0-ac1a-256df30025ce" class=""><strong>原因：</strong></p><p id="ed92d295-7835-4742-b245-7d9edc9fa96e" class="">因為大的 network 比較好訓練，可參照過去錄影：<a href="https://youtu.be/_VuWvQUMQVk">https://youtu.be/_VuWvQUMQVk</a></p><h3 id="1189fe2a-25e5-4934-a91e-f9704f15cb1e" class="">2.3.1 Lottery Ticket Hypothesis</h3><p id="750b754b-76e5-46bb-b3da-674424b3480b" class=""><a href="https://arxiv.org/abs/1803.03635">Lottery Ticket Hypothesis</a> 解釋為什麼大的 network 比較容易訓練（注意是”假說”）</p><p id="ed9ef62f-6526-4f80-b31c-40e46b5afd6c" class=""><strong>大的 network 可以視為是很多小的 sub-network 的組合</strong>，當訓練大的 network 時，等於是在訓練很多小的 network</p><figure id="ca38cea8-1199-45a5-a113-ff48e6c9ceca" class="image"><a href="14-Nerwork%20Compression/5.png"><img style="width:384px" src="14-Nerwork%20Compression/5.png"/></a></figure><p id="8fbbea33-b3db-40b4-973f-cabb54745644" class="">對於每個 sub-network 不一定可以訓練成功，不一定可以透過 gradient descent 找到好的解使 loss 變低。但只要有<strong>大量的 sub-network，其中一個成功，大的 network 就成功了</strong></p><p id="4f85b2c3-fe84-43f0-b412-3e272cb0cc8f" class=""><strong>實驗證明：</strong></p><p id="8dc0bd05-1ec5-4317-b51f-fd266c04af27" class="">將一參數是隨機初始化的大 network 訓練後進行 pruning 的到一個 pruned network</p><figure id="bc6a88a5-1321-4808-8807-a36825c356a2" class="image"><a href="14-Nerwork%20Compression/6.png"><img style="width:384px" src="14-Nerwork%20Compression/6.png"/></a></figure><p id="c2a6b710-cafc-44b9-ba1d-79d00e1c7267" class="">針對此 pruned network 分別採取兩個行為：</p><ul id="5b4d6241-660c-4c70-96a5-3eeb53b2fb05" class="bulleted-list"><li style="list-style-type:disc"><strong>參數隨機初始化進行訓練</strong>，實驗結果發現<strong>難以訓練成功</strong></li></ul><ul id="a0663b0a-0ac1-43b6-a521-678ee3f2549b" class="bulleted-list"><li style="list-style-type:disc"><strong>參數使用 pruning 前且訓練前 network</strong>，實驗結果發現<strong>可以訓練成功</strong></li></ul><p id="051ab537-2404-4121-b6b3-42180c915291" class=""><strong>解構 Lottery Ticket Hypothesis：</strong></p><figure id="9983ff05-5352-4050-89d1-11b8a04f601c" class="image"><a href="14-Nerwork%20Compression/7.png"><img style="width:432px" src="14-Nerwork%20Compression/7.png"/></a></figure><p id="9691cc17-8100-4960-9b83-4b992fdd4c92" class=""><strong>結論：</strong></p><ul id="7e856357-a4dc-4a07-8874-bedce3905c40" class="bulleted-list"><li style="list-style-type:disc">找到了兩種最為有效的 pruning strategy</li></ul><ul id="5b53f663-6d9b-40cc-8e1f-3bfc6e43ecab" class="bulleted-list"><li style="list-style-type:disc"><strong>正負號</strong>是 network 能不能被訓練起來的關鍵，絕對值事實上相對不重要</li></ul><ul id="7c01f4fc-8b5e-4423-a58a-3e99bc7152ce" class="bulleted-list"><li style="list-style-type:disc">隨機初始化 network，就已經可以對一些參數進行剪枝，並得到一個效果不錯的 network</li></ul><h3 id="53365cab-726d-4f35-a2a6-3473fb23f787" class="">2.3.2 反對大樂透假說：Rethinking the Value of Network Pruning</h3><figure id="efe428e1-b87f-40e0-82db-3b93b81c6230" class="image"><a href="14-Nerwork%20Compression/8.png"><img style="width:432px" src="14-Nerwork%20Compression/8.png"/></a></figure><ul id="d2ec21db-69e5-4378-8792-840c828be71d" class="bulleted-list"><li style="list-style-type:disc">對於 pruned 後的 network，作完全隨機的初始化，並經過更多 epoch 的訓練，也更得到比 pruned 後的 network 甚至 pruned 前的 network 更好的性能</li></ul><ul id="fb21b134-1ddf-4d8b-a96a-5e1549fa358e" class="bulleted-list"><li style="list-style-type:disc">大樂透假說可能只在某些條件下才觀察得到<ul id="310ce922-5a0c-43c6-bf8f-ee01a6ca24ae" class="bulleted-list"><li style="list-style-type:circle">小的 learning rate</li></ul><ul id="45a8a222-6bd3-4265-bf5f-f3247417e117" class="bulleted-list"><li style="list-style-type:circle">不規則的 network （刪除 weight）</li></ul></li></ul><h1 id="b685e458-7736-40f8-a29b-dc180426edbd" class="">3. Knowledge Distillation</h1><p id="0d2be484-6f7e-4958-9ec0-472ea4cc5082" class="">對於同一個任務，訓練兩個 network：</p><ul id="ed3b092d-2144-46f6-a9e3-65dda8d7e763" class="bulleted-list"><li style="list-style-type:disc"><strong>Teacher Network：</strong>大的 network，也可以是多個模型的 ensemble</li></ul><ul id="6a86ee3b-5269-49bb-894a-34a08aa1feaa" class="bulleted-list"><li style="list-style-type:disc"><strong>Student Network：</strong>小的 network，是真正想要訓練的 network</li></ul><figure id="263bc262-f5d2-4fae-95bf-83142290e221" class="image"><a href="14-Nerwork%20Compression/9.png"><img style="width:336px" src="14-Nerwork%20Compression/9.png"/></a></figure><p id="10c710f5-6375-4126-a894-1c78f9916936" class="">以手寫辨識為例，teacher network 輸出數字的機率分布，student network 的輸出也要是數字的機率分布，<strong>期望與 teacher network 的結果越接近越好</strong></p><h2 id="d08ae3ec-867d-4b8d-b761-607b104a2f04" class="">3.1 Temperature for softmax</h2><p id="8852ab24-d860-4b0c-8707-c04f35a89597" class="">輸出是經過 softmax 運算的結果，使每一個數字變為機率分布介於 0 和 1 之間</p><figure id="3bb81401-4307-4aa4-8639-bf01032c9853" class="image"><a href="14-Nerwork%20Compression/10.png"><img style="width:432px" src="14-Nerwork%20Compression/10.png"/></a></figure><p id="6f34642c-7abc-4010-a53b-1e988ab7ca01" class=""><strong>問題：</strong></p><p id="dd5123f2-1ca1-4aa0-8e25-c9ea3ec78768" class="">使用原始的 softmax 可能會有機率分布集中的問題，這樣與直接給予正確答案沒有什麼不同，對於 student network 來說沒有幫助，因為 teacher network 沒有提供額外的訊息</p><p id="c600ac91-cff0-48cd-818b-02069b0d07ce" class=""><strong>解決：</strong></p><p id="a4f51f27-05b6-4e93-8a85-1cb87fbf5dbb" class=""><strong>新增超參數 temperature </strong><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span></span><span>﻿</span></span>，使輸出的機率分布變得比較平滑</p><h1 id="68a6c9e7-5dea-4647-ac9e-0f8f8a9359dd" class="">4. Parameter Quantization</h1><h3 id="ec0e6dbe-a34f-4212-93c0-375abea0d386" class="">4.1 減少 bits 數</h3><p id="8722ec86-2161-4112-9f9e-0c64241bc46b" class="">使用較少的空間（bits）儲存一個參數。一般在存一個參數可能是用 64 bits，但可能不必用這麼高的精度，可能用 16 bits、8 bits 或更少就足夠了</p><h3 id="62e4fb84-e9b1-491a-baa0-2f14b4d3e8eb" class="">4.2 Weight clustering</h3><p id="24321c87-d87d-46e2-84f3-dfb49d1aeab3" class="">依參數數值接近程度<strong>將參數分群</strong>，讓<strong>同一群的參數有一樣的數值（取同群參數的平均）</strong>，並<strong>建立一個 table 記錄每一群的值</strong></p><figure id="649a976d-2f70-42b6-9f50-0810fecc8157" class="image"><a href="14-Nerwork%20Compression/11.png"><img style="width:432px" src="14-Nerwork%20Compression/11.png"/></a></figure><p id="41315f61-97b0-47fc-ace9-b3ff203d0a8e" class="">
</p><h3 id="9c6e28b0-876a-40f8-8681-c30d54e2e667" class="">4.3 Huffman encoding</h3><p id="a98ed693-77fb-4c5a-aaa4-abcf290b98e3" class="">較常出現的使用較少 bits；較少出現的使用較多 bits</p><h3 id="c001ae27-55e3-49d9-8bf5-1c2b0c97412b" class="">4.4 Binary weight</h3><p id="9bfbebda-6712-4778-8825-081c00e8b3e8" class="">只以正負 1 表示所有參數</p><figure id="91446eba-32c8-4951-acf6-f48c42f50428" class="image"><a href="14-Nerwork%20Compression/12.png"><img style="width:336px" src="14-Nerwork%20Compression/12.png"/></a></figure><h1 id="33971596-fb75-472f-803b-78b29a97cd0b" class="">5. Architecture Design</h1><h2 id="687ddfef-106d-46d2-8889-00b9c7d35fe8" class="">5.1 Low rank approximation</h2><p id="b9f6997a-f578-44c8-bcf0-82765aacec47" class="">輸入有 N 個 neuron，輸出有 M 個 neuron，兩層之間的參數量 W = N x M ，只要 N 跟 M 其中一者很大，W 的參數量就會很大</p><figure id="2fb68595-5551-4ca4-8dfa-fcf355297767" class="image"><a href="14-Nerwork%20Compression/13.png"><img style="width:384px" src="14-Nerwork%20Compression/13.png"/></a></figure><p id="3deaa146-d02f-4497-af2a-6c328a49be2a" class="">為了減少參數量，可在 N 跟 M 中間新增一層 layer，這一層的 neuron 數目是 K</p><p id="82618319-72c4-4c40-84f2-56f5ee923de3" class=""><strong>原參數量是 M x N</strong>；而新增一 neuron 數為 K 的 layer 後，<strong>參數量減少為 K x（N + M）</strong>，若 K 遠小於 M 跟 N，那麼 U 跟 V 的參數量加起來，會比 W 還少的多</p><p id="f7b72508-61e0-4876-bc25-161e9845c7a6" class=""><strong>問題：</strong></p><p id="06c48389-5a58-48b0-90e8-5dba5f9641c2" class="">W 分成用 U 跟 V 兩層來分開表示時，會減少 W 的可能性，W 的 rank 會 ≤ K</p><h2 id="0784a5da-6b6e-4332-ad3a-3bf169deee57" class="">5.2 Depthwise Separable Convolution</h2><h3 id="b8bf8641-6cbd-456e-9fac-db6ebc23c12f" class="">5.2.1 Depthwise Convolution</h3><p id="ee0a19eb-75da-4da0-b04f-eae452905b7f" class="">考慮一個 channel 的內部關係</p><figure id="dc9f855c-66f2-40ec-aeca-73ee55bf93e1" class="image"><a href="14-Nerwork%20Compression/14.png"><img style="width:384px" src="14-Nerwork%20Compression/14.png"/></a></figure><ul id="daec147d-3348-4da6-a5ec-75aba029e7a3" class="bulleted-list"><li style="list-style-type:disc">每個 filter 負責一個 channel</li></ul><ul id="cb2ab896-148e-4052-94b4-7daeeff342be" class="bulleted-list"><li style="list-style-type:disc">channel 數目和 filter 數目相同</li></ul><ul id="ff971b1b-9b22-43c7-8bd5-35ae556e6ec0" class="bulleted-list"><li style="list-style-type:disc">input channel 和 output channel 數目相同</li></ul><ul id="ed3bdd96-b691-488d-b238-56cd72ebe98c" class="bulleted-list"><li style="list-style-type:disc">channels 之間沒有互動</li></ul><h3 id="b43b38d5-b0fc-486e-9f1c-bb13596431f4" class="">5.2.2 Pointwise Convolution</h3><p id="9af45945-f10d-47c0-b956-9244bc7a1b1f" class="">考慮 channels 之間的關係</p><figure id="cede4fec-ba5a-4be3-90f4-09714a290826" class="image"><a href="14-Nerwork%20Compression/15.png"><img style="width:432px" src="14-Nerwork%20Compression/15.png"/></a></figure><p id="b7f2e632-cd36-4786-b650-f00be86e028d" class="">做完 depthwise convolution 後，進行 pointwise convolution</p><ul id="be5ae622-26ad-4092-84eb-cb87382fa65b" class="bulleted-list"><li style="list-style-type:disc">filter size 限制為 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span></li></ul><ul id="01cfb413-5ecc-4ea6-8af1-e84dcde25cf6" class="bulleted-list"><li style="list-style-type:disc">輸入 channel 和輸出 channel 的數目可以不同</li></ul><p id="ecbef877-7187-441a-9867-e2c227b0835a" class=""><strong>二者關係：</strong></p><p id="ab1cf7e6-4265-4124-a630-8337fae660a7" class="">觀察右側紅色左上角框內數據的來源，都是來自左側原圖中左上 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">3\times3\times2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span></span><span>﻿</span></span> 的區域，只是在 depthwise separable convolution中，將原來的一次卷積的操作改為兩次卷積，以此減少參數量</p><figure id="103bbcc5-008c-45dc-aea4-38e238e00c3a" class="image"><a href="14-Nerwork%20Compression/16.png"><img style="width:336px" src="14-Nerwork%20Compression/16.png"/></a></figure><p id="72ad3d4b-9dae-4c93-b884-388e0990bc94" class=""><strong>參數量變化：</strong></p><div id="66eb36cf-53c8-49cf-a894-85f6b9fddaed" class="column-list"><div id="d146fdee-1657-43e3-b16b-dbbe7281793c" style="width:50%" class="column"><figure id="56b2e678-7bb2-4807-863d-0eb826dcd675" class="image" style="text-align:right"><a href="14-Nerwork%20Compression/17.png"><img style="width:192px" src="14-Nerwork%20Compression/17.png"/></a></figure></div><div id="6efbff28-e89f-4889-b908-2086533483c2" style="width:50%" class="column"><figure id="b76ce4b7-4ca7-43b6-93e0-9638f38dad8b" class="image"><a href="14-Nerwork%20Compression/18.png"><img style="width:192px" src="14-Nerwork%20Compression/18.png"/></a></figure></div></div><p id="4bc3142d-19d6-4015-972a-c5519bbd9730" class=""><strong>實例：</strong></p><figure id="0a031034-0e02-4d8a-be76-3393c9415928" class="image"><a href="14-Nerwork%20Compression/19.png"><img style="width:336px" src="14-Nerwork%20Compression/19.png"/></a></figure><p id="b909983d-c726-4769-a885-9d4e9e469539" class="">左側為一般的卷積需要的參數量；右邊是 depthwise separable convolution 需要的參數量</p><p id="d4b6889b-d188-41a4-b76a-9941b4c3a0b2" class="">計算可得，兩者的參數量之比主要取決於 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{k\times k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span></p><h2 id="0a03eb59-6081-4295-9fa5-9a938289ed63" class="">5.3 To learn More</h2><ul id="84a6ffba-ec9b-4a25-a700-138a258e5435" class="bulleted-list"><li style="list-style-type:disc"><a href="https://arxiv.org/abs/1602.07360">SqueezeNet</a></li></ul><ul id="67681c81-2225-45b2-9d64-972e4c5316a9" class="bulleted-list"><li style="list-style-type:disc"><a href="https://arxiv.org/abs/1704.04861">MobileNet</a></li></ul><ul id="7b7cb3b3-bbe2-4e98-9b5c-5ee22c6b0211" class="bulleted-list"><li style="list-style-type:disc"><a href="https://arxiv.org/abs/1707.01083">ShuffleNet</a></li></ul><ul id="f0cded4e-3a77-4cdc-8bcc-b988ac8881af" class="bulleted-list"><li style="list-style-type:disc"><a href="https://arxiv.org/abs/1610.02357">Xception</a></li></ul><ul id="2df03d4c-d0c7-4bea-a5a1-63e38a50ca1c" class="bulleted-list"><li style="list-style-type:disc"><a href="https://arxiv.org/abs/1911.11907">GhostNet</a></li></ul><p id="889c2276-d073-4049-88ad-8c235974f733" class="">
</p><h1 id="ae0a6459-3ebf-48a5-9daa-0d060ff81133" class="">6. Dynamic Computation</h1><p id="ee8a8aad-9516-45bf-b950-ad189b84cf17" class="">希望 network 可以根據實際運算資源情況，自動調整需要的運算量</p><figure id="a11dddea-bfb9-4a54-a565-1610bcb1861e" class="image"><a href="14-Nerwork%20Compression/20.png"><img style="width:432px" src="14-Nerwork%20Compression/20.png"/></a></figure><h2 id="5c1522a3-f26f-4267-84b9-03fcc9a1b6a5" class="">6.1 Dynamic Depth</h2><p id="652cd1f0-5d33-4bb8-b87e-f6705911b85a" class="">在 layers 間<strong>加上 extra layers，</strong>extra layers 根據每一個 hidden layers 的輸出，<strong>中途決定分類的結果</strong></p><figure id="b4db00bd-e13b-4e3c-a009-bddedd09f00f" class="image"><a href="14-Nerwork%20Compression/21.png"><img style="width:432px" src="14-Nerwork%20Compression/21.png"/></a></figure><ul id="61ef7f5b-60de-48d6-a46e-978b4f4ae1c1" class="bulleted-list"><li style="list-style-type:disc"><strong>運算資源充足</strong>時，可讓圖片<strong>跑過所有的 layer</strong>，得到最終的分類結果</li></ul><ul id="68a053cf-9cc2-4477-b5aa-c718128b41b7" class="bulleted-list"><li style="list-style-type:disc"><strong>運算資源不足</strong>時，讓 network 決定要在哪一個 layer 自行做輸出</li></ul><p id="9250e584-9eab-45be-b4b0-3b44bcadd3eb" class="">期望 ground truth 跟每一個 extra layer 的輸出越接近越好，因此把所有的輸出跟 ground truth 的 cross entropy 加總得到 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span><span>﻿</span></span>，目標最小化 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span><span>﻿</span></span></p><p id="bd35c0dd-d62e-4501-b17b-2a2b5e41625f" class=""><strong>其他方法可參考論文：</strong><em><a href="https://arxiv.org/abs/1703.09844">Multi-Scale Dense Networks for Resource Efficient Image Classification</a></em><strong>（MSDNet）</strong></p><h2 id="2d486f9a-a5e6-47ef-9594-806f94a68e52" class="">6.2 Dynamic Width</h2><p id="3f47d2fc-4074-48fd-9344-af602ff13056" class="">在同一個 network 中，設定好幾個不同的寬度</p><figure id="05d4b26b-6bf8-4573-a552-312a2ca48d4e" class="image"><a href="14-Nerwork%20Compression/22.png"><img style="width:384px" src="14-Nerwork%20Compression/22.png"/></a></figure><p id="2d9185d6-c649-47fd-8dad-0617cc9c70ef" class="">將不同寬度的 network 產生的每一個輸出跟 ground truth 的差距加總得到 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span><span>﻿</span></span>，目標最小化 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span><span>﻿</span></span></p><h2 id="84ccf902-76fe-48cd-903c-4e05c25e251f" class="">6.3 network 自行決定深度和寬度</h2><p id="c95c8e4b-e9db-43fa-87ea-91264442537f" class="">根據<strong>輸入資料的難易程度</strong>，讓 network 自行決定執行的寬度和深度</p><figure id="5e5acff4-faf8-4bfa-b46b-d75bb2e60462" class="image"><a href="14-Nerwork%20Compression/23.png"><img style="width:384px" src="14-Nerwork%20Compression/23.png"/></a></figure><p id="ab19c233-05da-41aa-918f-a3c3047f05c8" class=""><strong>實現：</strong></p><ul id="c6b12dad-acc7-41a7-8f01-0dbe62cbbe89" class="bulleted-list"><li style="list-style-type:disc">SkipNet: Learning Dynamic Routing in Convolutional Networks</li></ul><ul id="821ffaf0-9b36-48c3-8ad2-ad5034563bd3" class="bulleted-list"><li style="list-style-type:disc">Runtime Neural Pruning</li></ul><ul id="3b3d571e-86c7-45e9-9b6b-bc381455835e" class="bulleted-list"><li style="list-style-type:disc">BlockDrop: Dynamic Inference Paths in Residual Networks</li></ul></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>